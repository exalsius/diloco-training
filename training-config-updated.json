{
  "model": "wav2vec2",
  "dataset": "librispeech",
  "local_steps": 128,
  "lr": 1e-05,
  "outer_lr": 0.8,
  "warmup_steps": 500,
  "total_steps": 3968,
  "per_device_train_batch_size": 64,
  "batch_size": 512,
  "optim_method": "sgd",
  "quantization": false,
  "async_communication": false,
  "checkpoint_path": "wav2vec2_librispeech_checkpoint.pth",
  "checkpoint_interval": 5,
  "hf_upload": true,
  "trained_model_hf_name": "exalsius/test_model_name",
  "device": "cuda",
  "gpu_type": "amd",
  "pgroup_backend": "gloo",
  "wandb_project_name": "test",
  "wandb_run_id": "wav2vec2_librispeech10",
  "wandb_group": "test_new_metrics",
  "heterogeneous": false,
  "min_batch_size": 16,
  "max_batch_size": 64,
  "group_perc_variance": 0.15,
  "compression_decay": 0.95,
  "compression_topk": 32,
  "experiment_description": "GPT-Neo-X training on C4 using DiLoCo distributed training",
  "experiment_tags": [
    "gpt_neo_x",
    "c4",
    "diloco",
    "distributed",
    "heterogeneous",
    "llm",
    "optim_sgd",
    "device_cuda"
  ],
  "seed": 42,
  "wandb_logging": true,
  "compile_model": false,
  "compile_backend": "inductor",
  "compile_mode": "default"
}