# Model and Dataset Configuration
model: "resnet50"
dataset: "imagenet"

# Training Hyperparameters
local_steps: 128
lr: 3e-4
outer_lr: 0.7
warmup_steps: 500
total_steps: 40000

# Batch Size Configuration
per_device_train_batch_size: 64
batch_size: 512

# Optimization Settings
optim_method: "sgd"

# Checkpoint Configuration
checkpoint_path: "wav2vec2_imagenet_checkpoint.pth"
checkpoint_interval: 5

# Device Configuration
device: "cuda"

# WandB Configuration
wandb_project_name: "test"
wandb_group: "4nodes-heterogeneous-scratch"
wandb_run_id: "wav2vec30"

# Advanced Features
heterogeneous: true
compression_decay: 0.95
compression_topk: 32

# Experiment Metadata
experiment_description: "Wav2Vec2 training on LibriSpeech using DiLoCo distributed training"
experiment_tags:
  - "wav2vec2"
  - "librispeech"
  - "diloco"
  - "distributed"
  - "heterogeneous"
  - "llm"
seed: 42
wandb_logging: true

# torch.compile settings
compile_model: false
compile_backend: "inductor"
compile_mode: "default"